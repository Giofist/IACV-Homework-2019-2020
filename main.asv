%% clear all and instantiate variables
clc
clear all
debug = false; %if True display all the images (intermediate passages and choices) else displays only most relevant images
auto_selection = true; %if true automatic line selection, if false manual line selection
ceck_with_second_image = false;  %if true it passes the second image to the algorithm

% global variables used in other functions
global WINDOW_SIZE LINES_ORIZONTAL_LEFT LINES_VERTICAL_LEFT LINES_ORIZONTAL_RIGHT ...
        LINES_VERTICAL_RIGHT LINES_VERTICAL_EXTRA LINES_ORIZONTAL_EXTRA TOP_LINE_LW TOP_LINE_RW ...
        IMG_MAX_SIZE_X IMG_MAX_SIZE_Y IMG_MAX_SIZE
       
% constants for line selection

LINES_ORIZONTAL_LEFT = 1;
LINES_VERTICAL_LEFT = 2;
LINES_ORIZONTAL_RIGHT = 3;
LINES_VERTICAL_RIGHT = 4;
LINES_VERTICAL_EXTRA = 5;
LINES_ORIZONTAL_EXTRA = 6;
TOP_LINE_LW = 7;
TOP_LINE_RW = 8;
IMG_MAX_SIZE_X;
IMG_MAX_SIZE_Y;
IMG_MAX_SIZE;
% length of the longside of horizontal faces
WINDOW_SIZE = 1000;   %1 meter

%% Open the Image

if ceck_with_second_image
    image_input = 'Image2.jpg';
    auto_selection = false; 
else
    image_input = 'Image1.jpg';
end 

im_rgb = imread(image_input);
IMG_MAX_SIZE = max(size(im_rgb));
[x, y] =size(im_rgb);
IMG_MAX_SIZE_X = x;
IMG_MAX_SIZE_Y = y/3; %fro RGB

if debug
    figure(1), imshow(im_rgb); title('Original Image');
end
%% Image GrayScale Conversion
im_gray = rgb2gray(im_rgb);

if debug
    figure(1),imshow(im_gray);title('Grayscale Image');
end

%% Image shadow and light normalization
im_gray_norm = adapthisteq(im_gray);

if debug
    im_gray_imadjust = imadjust(im_gray);
    im_gray_histeq = histeq(im_gray);
    montage({im_gray, im_gray_imadjust, im_gray_histeq, im_gray_norm, adapthisteq(im_gray_norm)},'Size',[1 5])
    title("Original Image and Enhanced Images using imadjust, histeq, and adapthisteq")
end

% for a better result I decided to apply the normalization twice
im_gray_norm = adapthisteq(im_gray_norm);

if debug
    figure(1),imshow(im_gray_norm);title('Grayscale Image Twice normalized');
end

%% Line extraction
lines = extract_lines(im_gray_norm, debug, "canny", ceck_with_second_image);

% plot lines on the image
draw_lines(lines, im_rgb);

%% Stratification approach:
% - compute affine reconstruction
% l_inf -> l_inf (the line at infinity must be mapped to itself)
% H_r_aff = [1  0  0
%            0  1  0
%            l1 l2 l3] where the last row is l_inf'

% Extract parallel lines

[line_ind_olw, lines_olw] = pick_lines(lines,im_rgb,"Select two or more orizontal parallel lines on left window (then press enter):",auto_selection, LINES_ORIZONTAL_LEFT);
[line_ind_vlw, lines_vlw] = pick_lines(lines,im_rgb,"Select two or more vertical parallel lines on left window (then press enter):", auto_selection, LINES_VERTICAL_LEFT);
[line_ind_orw, lines_orw] = pick_lines(lines,im_rgb,"Select two or more orizontal parallel lines on right window (then press enter):", auto_selection, LINES_ORIZONTAL_RIGHT);
[line_ind_vrw, lines_vrw] = pick_lines(lines,im_rgb,"Select two or more vertical parallel lines on right window (then press enter):", auto_selection, LINES_VERTICAL_RIGHT);
[line_ind_vextra, lines_vextra] = pick_lines(lines,im_rgb,"Select two or more vertical parallel lines (then press enter):", auto_selection, LINES_VERTICAL_EXTRA);
[line_ind_oextra, lines_oextra] = pick_lines(lines,im_rgb,"Select two or more orizontal parallel lines (then press enter):", auto_selection, LINES_ORIZONTAL_EXTRA);
% plot selected lines
line_ind = [line_ind_olw, line_ind_vlw, line_ind_orw, line_ind_vrw, line_ind_oextra];
draw_lines(lines(1,line_ind), im_rgb);

%% extract the line at infinite

% get vanishing points
vp_olw = getVp(lines_olw);
vp_vlw = getVp(lines_vlw);
vp_orw = getVp(lines_orw);
vp_vrw = getVp(lines_vrw);
vp_vextra = getVp(lines_vextra);
vp_oextra = getVp(lines_oextra);

%vp = [vp_olw vp_vlw vp_orw vp_vrw vp_vextra vp_oextra];
vp = [vp_olw vp_vlw vp_orw vp_vrw, vp_oextra];

%visualize vanishing lines and points
draw_lines_infinity(lines(1,line_ind), im_rgb, vp);
    
    
% fit the line through these points
%l_inf_prime = fitLine([vp_olw vp_vlw vp_orw vp_vrw],false);
l_inf_prime = fitLine([vp_olw vp_oextra],true);

%% compute H_r_aff

H_r_aff = [1 0 0; 0 1 0; l_inf_prime(1) l_inf_prime(2) l_inf_prime(3)];

% Transform the image
img_affine = transform_and_show(H_r_aff, im_rgb, "Affine rectification XZ");


%% Metric rectification
% In order to perform metric rectification from an affine transformation we
% need perpendicular lines for constraints of the C_star_inf'

perpLines = [createLinePairsFromTwoSets(lines_olw, lines_oextra), createLinePairsFromTwoSets(lines_olw, lines_vextra)];

% transform lines according to H_r_aff since we need to start from an affinity
perpLines = transformLines(H_r_aff, perpLines);

% Ceck if transformed lines are good (TODO)

%% compute H through linear reg starting from affine transformation

ls = [];
ms = [];
index = 1;
for ii = 1:2:size(perpLines,2)
    ls(:, index) = perpLines(:, ii);
    ms(:, index) = perpLines(:, ii+1);
    index = index + 1;
end

% fit the transformation from affinity to euclidean
H_a_e = compute_H_aff(ls,ms, debug);

%% Transform from affinity
img_affine_scaled = imresize(img_affine, 0.2);
tform = projective2d(H_a_e.');

% apply the transformation to img
outputImage = imwarp(img_affine_scaled, tform);
R = rotx(deg2rad(180));
tform = projective2d(R.');
outputImage = imwarp(outputImage, tform);
outputImage = imrotate(imresize(outputImage, [IMG_MAX_SIZE_X, IMG_MAX_SIZE_Y]), -88);

figure();
imshow(outputImage);
title('Affine transformation');

%% Complete Transformation

Resize = [0.2 0 0; 0 0.2 0; 0 0 1];
O = rotz(deg2rad(-88));
H_r_complete = Resize * R * O * H_a_e * H_r_aff;
 
tform_complete = projective2d(H_r_complete.');
outputImage_final = imwarp(im_rgb, tform_complete);
%outputImage_final = imresize(outputImage_final, [IMG_MAX_SIZE_X, IMG_MAX_SIZE_Y]);

figure();
imshow(outputImage_final);
title('Affine transformation');

%% metric
H_metric = [1 0 0; 0 164/109 0; 0 0 1];
tform_metric = projective2d(H_metric.');
outputImage_metric = imwarp(outputImage_final, tform_metric);

figure();
imshow(outputImage_metric);
title('Metric reconstruction');

H_fin = H_metric * H_r_complete;

%% Estimate calibtation matrix K
% We can use skew simmetry but not natural camera assumption!!!
% the matrix we're looking for is:
%               |w1  0   w3|
%           w=  |0   w2  w4|
%               |w3  w4  w5|
%We need 5 constraint 3 form vanishing points and 2 form H matrix

%calculation of K from IAC using constraints (p226)
A = [vp_olw(1)*vp_vlw(1), vp_olw(2)*vp_vlw(2),   vp_olw(1)+vp_vlw(1),  vp_olw(2)+vp_vlw(2),  1;
    vp_olw(1)*vp_oextra(1),   vp_olw(2)*vp_oextra(2),  vp_olw(1)+vp_oextra(1),   vp_olw(2)+vp_oextra(2),   1;
    vp_oextra(1)*vp_vlw(1),   vp_oextra(2)*vp_vlw(2),  vp_oextra(1)+vp_vlw(1),   vp_oextra(2)+vp_vlw(2),   1;
    H_fin(1,1)*H_fin(2,1),  H_fin(1,2)*H_fin(2,2),  H_fin(1,3)*H_fin(2,1)+H_fin(1,1)*H_fin(2,3), H_fin(1,3)*H_fin(2,2)+H_fin(1,2)*H_fin(2,3), H_fin(1,3)*H_fin(2,3)];
aus = null(A);
IAC = [aus(1), 0, aus(3); 0, aus(2), aus(4); aus(3),aus(4),aus(5)];
K_g = chol(IAC);
K_g = inv(K_g);
K_g = K_g/K_g(3,3);

% %% Estimate calibtation matrix K second attempt not working!!!
% % We can use skew simmetry but not natural camera assumption!!!
% % the matrix we're looking for is:
% 
% %calculation of K from IAC using constraints (p226)zz
% A = [vp_olw(1)*vp_vlw(1), vp_olw(2)*vp_vlw(2),   vp_olw(1)+vp_vlw(1),  vp_olw(2)+vp_vlw(2),  1;
%     vp_olw(1)*vp_oextra(1),   vp_olw(2)*vp_oextra(2),  vp_olw(1)+vp_oextra(1),   vp_olw(2)+vp_oextra(2),   1;
%     vp_oextra(1)*vp_vlw(1),   vp_oextra(2)*vp_vlw(2),  vp_oextra(1)+vp_vlw(1),   vp_oextra(2)+vp_vlw(2),   1;
%     H_fin(1,1)*H_fin(2,1), H_fin(1,2)*H_fin(2,2),  H_fin(1,3)*H_fin(2,1)+H_fin(1,1)*H_fin(2,3), H_fin(1,3)*H_fin(2,2)+H_fin(1,2)*H_fin(2,3), H_fin(1,3)*H_fin(2,3);
%     H_fin(1,1)^2-H_fin(2,1)^2, H_fin(1,2)^2-H_fin(2,2)^2,   2*(H_fin(1,3)*H_fin(1,1)-H_fin(2,3)*H_fin(2,1)),    2*(H_fin(1,3)*H_fin(1,2)-H_fin(2,3)*H_fin(2,2)),   H_fin(1,3)^2-H_fin(2,3)^2];
% aus = null(A);
% IAC = [aus(1), 0, aus(3); 0, aus(2), aus(4); aus(3),aus(4),aus(5)];
% K_g2 = chol(IAC);
% K_g2 = inv(K_g2);
% K_g2 = K_g2/K_g2(3,3);

%% Estimate K from normalized vp Second test
% for double ceck but assuming also natural camera!!!
A = [vp_olw(1)*vp_vlw(1)+vp_olw(2)*vp_vlw(2),vp_olw(1)+vp_vlw(1),vp_olw(2)+vp_vlw(2),1;
    vp_olw(1)*vp_oextra(1)+vp_olw(2)*vp_oextra(2),vp_olw(1)+vp_oextra(1),vp_olw(2)+vp_oextra(2),1;
    vp_oextra(1)*vp_vlw(1)+vp_oextra(2)*vp_vlw(2),vp_oextra(1)+vp_vlw(1),vp_oextra(2)+vp_vlw(2),1];
aus = null(A);
IAC = [aus(1), 0, aus(2); 0, aus(1), aus(3); aus(2),aus(3),aus(4)];
K_n = chol(IAC);
K_n = inv(K_n);
K_n = K_n/K_n(3,3);

%% Online K computation GOOD RESULT
% Using L_inf, vertical vp and homography
H_scaling = diag([1/IMG_MAX_SIZE_X, 1/IMG_MAX_SIZE_Y, 1]);
l_infs = H_scaling.' \ l_inf_prime;
vp_vertical = H_scaling * vp_vlw;

IAC = get_IAC(l_infs, vp_vertical, [], [], H_scaling/H_fin);

% get the intrinsic parameter before the denormalization
alfa = sqrt(IAC(1,1));
u0 = -IAC(1,3)/(alfa^2);
v0 = -IAC(2,3);
fy = sqrt(IAC(3,3) - (alfa^2)*(u0^2) - (v0^2));
fx = fy /alfa;

% build K using the parametrization
K = [fx 0 u0; 0 fy v0; 0 0 1];

% denormalize K
K = H_scaling \ K

% get intrinsic after denormalization
fx = K(1,1);
fy = K(2,2);
u0 = K(1,3);
v0 = K(2,3);
alfa = fx/fy;


%% Reconstruction of main facade  (TO BE FIXED)

% a=intersection(lines(11), lines(140));
% b=intersection(lines(11), lines(139));
% c=intersection(lines(139), lines(138));
% d=intersection(lines(140), lines(138));
a = [3144, 1125];
b = [3477, 935];
c = [3886, 1353];
d = [3479, 1568];

b1 = b-a+[K(1,3), K(2,3)];
c1 = c-a+[K(1,3), K(2,3)];
d1 = d-a+[K(1,3), K(2,3)];
a1 = [K(1,3), K(2,3)];
%scalo rispetto a fx e fy
ratio_c = norm(a1-c1)/K(2,2);
c_new = [a1(1)+(c1(1)-a1(1))*ratio_c, a1(2)+(c1(2)-a1(2))*ratio_c,1]';
ratio_b = norm(a1-b1)/K(1,1);
b_new = [a1(1)+(b1(1)-a1(1))*ratio_b, a1(2)+(b1(2)-a1(2))*ratio_b,1]';
d_new = cross(cross(b_new,vv),cross(c_new,vh1));
d_new = d_new/d_new(3);
a_new = a1;
%riporto a dov'era prima
a_new = a_new-[K(1,3), K(2,3)]+a;
b_new = b_new-[K(1,3), K(2,3)]+a;
c_new = c_new-[K(1,3), K(2,3)]+a;
d_new = d_new-[K(1,3), K(2,3)]+a;
%come output uso fx e fy
out = [0 0;K(1,1),0;0,K(2,2);K(1,1),K(2,2)];


%%

% % K_g = [0.01 0 0; 0 0.01 0; 0 0 1] * K_g;
% % tform_k = projective2d(K_g.');
% % outputImage_k = imwarp(im_rgb, tform_k);
% % 
% % figure();
% % imshow(outputImage_k);
% % title('Affine transformation using K');
% %IAC_from_K = (K*K.')^-1;
% %IAC_from_K = IAC_from_K/IAC_from_K(3,3);
% 
% %% Localization of camera position and orientation
% 
% x_dl = [0 0];
% x_ul = [0 LENGTH_LONGSIDE];
% % x_dr = [LENGTH_LONGSIDE/aspect_ratio_left 0];
% % x_ur = [LENGTH_LONGSIDE/aspect_ratio_left LENGTH_LONGSIDE];
% 
% % get the same points in the original image
% % get useful lines
% l_left = lines_left_face(:,1);
% l_up = lines_left_face(:,2);
% l_down = lines_left_face(:,3);
% l_right = lines_left_face(:,4);
% 
% % upper left point and down left point
% x_ul_left = cross(l_left,l_up);
% x_dl_left = cross(l_left,l_down);
% 
% % upper right point and down right point
% x_ur_left = cross(l_right,l_up);
% x_dr_left = cross(l_down,l_right);
% 
% % normalization
% x_ul_left = x_ul_left ./ x_ul_left(3,1); 
% x_dl_left = x_dl_left ./ x_dl_left(3,1);
% x_ur_left = x_ur_left./ x_ur_left(3,1);
% x_dr_left = x_dr_left./ x_dr_left(3,1);
% 
% % fit the homography from scene to image 
% H_omog = fitgeotrans([x_ul; x_dl; x_ur; x_dr], [x_ul_left(1:2).'; x_dl_left(1:2).'; x_ur_left(1:2).'; x_dr_left(1:2).'], 'projective');
% H_omog = H_omog.T.';
% 
% % extract columns
% h1 = H_omog(:,1);
% h2 = H_omog(:,2);
% h3 = H_omog(:,3);
% 
% % normalization factor.
% lambda = 1 / norm(K \ h1);
% 
% % r1 = K^-1 * h1 normalized
% r1 = (K \ h1) * lambda;
% r2 = (K \ h2) * lambda;
% r3 = cross(r1,r2);
% 
% % rotation of the world with respect to the camera (R cam -> world)
% % where the world in this case is the left horizontal face
% R = [r1, r2, r3];
% 
% % due to noise in the data R may be not a true rotation matrix.
% % approximate it through svd, obtaining a orthogonal matrix
% [U, ~, V] = svd(R);
% R = U * V';
% 
% % Compute translation vector. This vector is the position of the plane wrt
% % the reference frame of the camera.
% T = (K \ (lambda * h3));
% 
% cameraRotation = R.';
% % since T is expressed in the camera ref frame we want it in the plane
% % reference frame, R.' is the rotation of the camera wrt the plane
% cameraPosition = -R.'*T;
% 
% 
% %% Display orientation and position from left horizontal face
% 
% figure
% plotCamera('Location', cameraPosition, 'Orientation', cameraRotation.', 'Size', 20);
% hold on
% pcshow([[x_ul; x_dl; x_ur; x_dr], zeros(size([x_ul; x_dl; x_ur; x_dr],1), 1)], ...
%     'red','VerticalAxisDir', 'up', 'MarkerSize', 20);
% xlabel('X')
% ylabel('Y')
% zlabel('Z')